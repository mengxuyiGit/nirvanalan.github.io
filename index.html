<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xuyi Meng</title>

  <meta name="author" content="Xuyi Meng">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Yushi Lan</name>
                  </p>
                  <p>
                    I am currently a 1st-year computer science M.S. student at <a href="mmlab-ntu.com">MMLab@NTU</a>,
                    <a href="https://www.ntu.edu.sg/">Nanyang Technological University</a>,
                    supervised by <a href="https://www.mmlab-ntu.com/person/ccloy/">Prof. Chen Change Loy</a> and
                    working closely with <a href="daibo.info">Dr. Daibo</a>.
                    I got my bachelor degree in software engineering from Yepeida Honors College,
                    <a href="https://www.bupt.edu.cn">Beijing Univ of Posts and Tele (BUPT)</a> in 2020.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:lanyushi15@gmail.com">Email</a> &nbsp/&nbsp
                    <a href="data/CV-Yushi Lan-2023.Sept.pdf">CV</a> &nbsp/&nbsp
                    <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                    <!-- <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> -->
                    <!-- &nbsp/&nbsp -->
                    <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                    <a href="https://github.com/NIRVANALAN/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">

                  <a href="images/portrait-yslan.JPG"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/yslan-indo.jpeg" class="hoverZoomLink"></a>

                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    My interests lie in the intersection of computer vision, computer graphics, and machine learning,
                    particularly in inverse graphics powered by neural rendering,
                    including 3D generative models, shape analysis and 3D avatar, etc.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

<!-- ! below section TODO, after new paper accepted. -->
<!-- 
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <p> [2023-06] Joined Google AR as a student researcher, working with <a href="https://www.zhangyinda.com/">Yinda Zhang</a> .</p>
                  <p> [2023-03] Joined Google AR as a student researcher, working with <a href="https://www.zhangyinda.com/">Yinda Zhang</a> .</p>
                </td>
              </tr>
            </tbody>
          </table> -->


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <!-- iclr 23 -->


              <!-- <div class="teaser-container">
                <img class="teaser" src="/assets/images/EVA3D.gif" alt="EVA3D.gif">
              </div> -->

              <!-- <div class="info-container">

                <p class="title">

                  <a class="title_link" href="https://arxiv.org/abs/2210.04888" target="_blank">EVA3D: Compositional 3D
                    Human Generation from 2D Image Collections
                  </a>

                </p>

                <div class="authors">
                  <a href="https://hongfz16.github.io/" target="_blank">Fangzhou Hong</a>,
                  <a href="https://frozenburning.github.io/" target="_blank"> Zhaoxi Chen</a>,
                  <strong>Yushi Lan</strong>,
                  <a href="https://scholar.google.com/citations?user=lSDISOcAAAAJ&amp;hl=zh-CN" target="_blank">Liang
                    Pan</a>,
                  <a href="https://liuziwei7.github.io" target="_blank">Ziwei Liu</a></p>
                </div>

                <div class="conference">
                  <p><em>International Conference on Learning Representations</em> (<strong>ICLR</strong>), 2023 <span
                      style="color:red;"><strong>(Spotlight)</strong></span></p>
                </div>


                <div class="url">
                  <a href="https://arxiv.org/pdf/2210.04888.pdf" target="_blank">[PDF]</a>
                  <a href="https://hongfz16.github.io/projects/EVA3D.html" target="_blank">[Project Page]</a>
                  <a href="https://www.youtube.com/watch?v=JNV0FJ0aDWM" target="_blank">[Demo]</a>
                  <a href="https://www.unite.ai/creating-full-body-deepfakes-by-combining-multiple-nerfs/"
                    target="_blank">[Press]</a>
                  <a href="https://github.com/hongfz16/EVA3D" target="_blank">[Code]</a>
                  <img src="https://img.shields.io/github/forks/hongfz16/EVA3D?style=social">

                </div>

                <div class="comment">
                  <p>EVA3D is a <strong>high-quality unconditional 3D human generative model</strong> that only requires
                    2D image collections for training.</p>
                </div>

              </div> -->

              <!-- ln3diff -->

              <tr onmouseout="e3dge_stop()" onmouseover="e3dge_start()">
                <!-- <tr> -->
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='e3dge_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/ln3diff/mast.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <!-- <img src='images/gaussian3diff/small_teaser.png' width="160"> -->
                  </div>
                  <!-- <p>A sailboat with mast.</p> -->
                  <!-- <script type="text/javascript">
                    function e3dge_start() {
                      document.getElementById('e3dge_image').style.opacity = "1";
                    }

                    function e3dge_stop() {
                      document.getElementById('e3dge_image').style.opacity = "0";
                    }
                    e3dge_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://nirvanalan.github.io/projects/ln3diff/">
                    <papertitle>LN3Diff: Scalable Latent Neural Fields Diffusion for Speedy 3D Generation
                    </papertitle>
                  </a>
                  <br>

                  <strong>Yushi Lan</strong>,

                  <a href="https://hongfz16.github.io">Fangzhou Hong</a>,
                  <a href="https://williamyang1991.github.io/">Shuai Yang</a>,
                  <a href="https://shangchenzhou.com/">Shangchen Zhou</a>,
                  <a href="https://sg.linkedin.com/in/xuyi-meng-673779208">Xuyi Meng</a>,
                  <a href="https://daibo.info/">Bo Dai</a>,
                  <a href="https://xingangpan.github.io/">Xingang Pan</a>,
                  <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a>
                  <br>
                  <em>arXiv preprint</em>
                  <br>
                  <a href="https://nirvanalan.github.io/projects/ln3diff/">project page</a>
                  /
                  <a href="https://arxiv.org/pdf/2403.12019.pdf">arXiv</a>

                  <p></p>
                  <p>
                    LN3Diff creates high-quality 3D object mesh from text within 8 SECONDS. 
                  </p>
                </td>
              </tr>

              <!-- gaussian3diff -->

              <tr onmouseout="e3dge_stop()" onmouseover="e3dge_start()">
                <!-- <tr> -->
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='e3dge_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/dreamfusion.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div> -->
                    <img src='images/gaussian3diff/small_teaser.png' width="160">
                  </div>
                  <!-- <script type="text/javascript">
                    function e3dge_start() {
                      document.getElementById('e3dge_image').style.opacity = "1";
                    }

                    function e3dge_stop() {
                      document.getElementById('e3dge_image').style.opacity = "0";
                    }
                    e3dge_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://nirvanalan.github.io/projects/gaussian3diff/">
                    <papertitle>Gaussian3Diff: 3D Gaussian Diffusion for 3D Full Head Synthesis and Editing
                    </papertitle>
                  </a>
                  <br>

                  <strong>Yushi Lan</strong>,

                  <a href="https://scholar.google.com/citations?hl=en&user=qsrpuKIAAAAJ">Feitong
                    Tan</a>,
                  <a href="https://sylqiu.github.io/">Di Qiu</a>,
                  <a href="https://xharlie.github.io/">Qiangeng Xu</a>
                  <a href="https://www.kylegenova.com/">Kyle Genova</a>
                  <a href="https://zeng.science/">Zeng Huang</a>,
                  <a href="https://www.seanfanello.it/">Sean Fanello</a>,
                  <a href="https://scholar.google.com/citations?user=lJ3VfV8AAAAJ&hl=en">Rohit Pandey</a>,
                  <a href="https://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>,
                  <a href='https://www.mmlab-ntu.com/person/ccloy/' target='_blank'>Chen Change Loy</a>,
                  <a href="https://www.zhangyinda.com/">Yinda Zhang</a>
                  <br>
                  <em>arXiv preprint</em>
                  <br>
                  <a href="https://nirvanalan.github.io/projects/gaussian3diff/">project page</a>
                  /
                  <a href="https://arxiv.org/pdf/2312.03763.pdf">arXiv</a>

                  <p></p>
                  <p>
                    Gaussian3Diff adopts 3D Gaussians defined in UV space as the underlying 3D
                    representation, which intrinsically support high-quality novel view synthesis, 3DMM-based animation
                    and 3D diffusion for unconditional generation.
                  </p>
                </td>
              </tr>

              <!-- aaai24 -->


              <tr onmouseout="e3dge_stop()" onmouseover="e3dge_start()">
                <!-- <tr> -->
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <!-- <div class="two" id='e3dge_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/dreamfusion.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div> -->
                    <img src='./images/planedict.png' width="160">
                  </div>
                  <!-- <script type="text/javascript">
                    function e3dge_start() {
                      document.getElementById('e3dge_image').style.opacity = "1";
                    }

                    function e3dge_stop() {
                      document.getElementById('e3dge_image').style.opacity = "0";
                    }
                    e3dge_stop()
                  </script> -->
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://songlin1998.github.io/planedict/">
                    <papertitle>Learning Dense Correspondence for NeRF-Based Face Reenactment
                    </papertitle>
                  </a>
                  <br>

                  <a href="https://songlin1998.github.io/">Songlin Yang</a>, 
                  <a href="http://cripac.ia.ac.cn/people/wwang/index.html">Wei Wang</a>, 
                  <strong>Yushi Lan</strong>, 
                  <a href="https://events.keep.edu.hk/cuhk/engg5700/2017/team/fan-xiangyu/">Xiangyu Fan</a>, 
                  <a href="http://cripac.ia.ac.cn/en/EN/column/item139.shtml">Bo Peng</a>, 
                  <a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=jZH2IPYAAAAJ">Lei Yang</a>, 
                  <a href="http://cripac.ia.ac.cn/people/jdong/">Jing Dong</a>

                  <br>
                  <em>AAAI</em>, 2024
                  <br>
                  <!-- <a href="https://nirvanalan.github.io/projects/gaussian3diff/">project page</a> -->
                  <a href="https://songlin1998.github.io/planedict/">project page</a> /
                  <a href="https://arxiv.org/abs/2312.10422">arXiv</a>

                  <p></p>
                  <p>
                    We propose a novel face reenactment framework, 
                    which adopts tri-planes as fundamental NeRF representation and decomposes face tri-planes into three components: canonical tri-planes, identity deformations, and motion. 
                  </p>
                </td>
              </tr>


              <!-- iccv23 -->
              <!-- <tr> -->
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='e3dge_image'><video width=100% height=100% muted autoplay loop>
                      <source src="images/dreamfusion.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video></div>
                  <img src='images/deformtoon3d/deformtoon3d.png' width="160">
                </div>
                <!-- <script type="text/javascript">
                  function e3dge_start() {
                    document.getElementById('e3dge_image').style.opacity = "1";
                  }

                  function e3dge_stop() {
                    document.getElementById('e3dge_image').style.opacity = "0";
                  }
                  e3dge_stop()
                </script> -->
              </td>


              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://www.mmlab-ntu.com/project/deformtoon3d/">
                  <papertitle>DeformToon3D: Deformable 3D Toonification from Neural Radiance Fields
                  </papertitle>
                </a>
                <br>

                <a href='https://junzhezhang.github.io/' target='_blank'>Junzhe Zhang*</a>,
                <strong>Yushi Lan*</strong>,
                <a href='https://williamyang1991.github.io/' target='_blank'>Shuai Yang</a>,
                <a href="https://hongfz16.github.io/" target="_blank">Fangzhou Hong</a>,
                <a href="https://scholar.google.com/citations?user=KmxEHm4AAAAJ&hl=zh-TW&citsig=AMD79oqVxlhCocLzrBL2zNFZqVusRRfYow"
                  target="_blank">Quan Wang</a>,
                <a href="https://personal.ntu.edu.sg/asckyeo/" target="_blank">Chai Kiat Yeo</a>,
                <a href="https://liuziwei7.github.io" target="_blank">Ziwei Liu</a>,
                <a href='https://www.mmlab-ntu.com/person/ccloy/' target='_blank'>Chen Change Loy</a>
                <br>
                <em>ICCV</em>, 2023
                <br>
                <a href="https://www.mmlab-ntu.com/project/deformtoon3d/">project page</a>
                /
                <a href="https://arxiv.org/abs/2309.04410">arXiv</a>
                /
                <!-- <a href="https://drive.google.com/file/d/1yDkJfJOLeVlON7ZdRSnR34Ra_ikTVI0A/preview">video</a> -->

                <a href="https://github.com/junzhezhang/DeformToon3D">Code</a>

                <p></p>
                <p>
                  We propose DeformToon3D, an 3D toonification methods that achieves high-quality geometry and texture
                  stylization under given styles.
                </p>
              </td>

      </tr>

      <tr onmouseout="e3dge_stop()" onmouseover="e3dge_start()">
        <!-- <tr> -->
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <!-- <div class="two" id='e3dge_image'><video width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video></div> -->
            <img src='images/E3DGE/e3dge.png' width="160">
          </div>
          <!-- <script type="text/javascript">
            function e3dge_start() {
              document.getElementById('e3dge_image').style.opacity = "1";
            }

            function e3dge_stop() {
              document.getElementById('e3dge_image').style.opacity = "0";
            }
            e3dge_stop()
          </script> -->
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://nirvanalan.github.io/projects/E3DGE/index.html">
            <papertitle>E3DGE: Self-Supervised Geometry-Aware Encoder for Style-Based 3D GAN Inversion
            </papertitle>
          </a>
          <br>

          <strong>Yushi Lan</strong>,
          <a href='' target='_blank'>Xuyi Meng</a>,
          <a href='https://williamyang1991.github.io/' target='_blank'>Shuai Yang</a>,
          <a href='https://www.mmlab-ntu.com/person/ccloy/' target='_blank'>Chen Change Loy</a>,
          <a href='https://daibo.info/' target='_blank'>Bo Dai</a>
          <br>
          <em>CVPR</em>, 2023
          <br>
          <a href="https://nirvanalan.github.io/projects/E3DGE/index.html">project page</a>
          /
          <a href="https://arxiv.org/abs/2212.07409">arXiv</a>
          /
          <a href="https://drive.google.com/file/d/1yDkJfJOLeVlON7ZdRSnR34Ra_ikTVI0A/preview">video</a>
          /
          <a href="https://github.com/NIRVANALAN/CVPR23-E3DGE">Code</a>

          <p></p>
          <p>
            We propose E3DGE, an encoder-based 3D GAN inversion framework that yields high-quality shape and
            texture reconstruction.
          </p>
        </td>
      </tr>



      <!-- eva3d -->
      <tr onmouseout="e3dge_stop()" onmouseover="e3dge_start()">
        <!-- <tr> -->
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='e3dge_image'><video width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video></div>
            <img src='images/eva3d.gif' width="160">
          </div>
          <!-- <script type="text/javascript">
            function e3dge_start() {
              document.getElementById('e3dge_image').style.opacity = "1";
            }

            function e3dge_stop() {
              document.getElementById('e3dge_image').style.opacity = "0";
            }
            e3dge_stop()
          </script> -->
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://arxiv.org/abs/2210.04888">
            <papertitle>EVA3D: Compositional 3D Human Generation from 2D Image Collections
            </papertitle>
          </a>
          <br>
          <a href="https://hongfz16.github.io/" target="_blank">Fangzhou Hong</a>,
          <a href="https://frozenburning.github.io/" target="_blank"> Zhaoxi Chen</a>,
          <strong>Yushi Lan</strong>,
          <a href="https://scholar.google.com/citations?user=lSDISOcAAAAJ&amp;hl=zh-CN" target="_blank">Liang
            Pan</a>,
          <a href="https://liuziwei7.github.io" target="_blank">Ziwei Liu</a>
          <br>
          <em>ICLR</em>, 2023, <strong>Spotlight</strong>
          <br>
          <a href="https://hongfz16.github.io/projects/EVA3D.html">project page</a>
          /
          <a href="https://arxiv.org/pdf/2210.04888.pdf">arXiv</a>
          /
          <a href="https://www.youtube.com/watch?v=JNV0FJ0aDWM">video</a>
          /
          <a href="https://github.com/hongfz16/EVA3D">Code</a>
          <p></p>
          <p>EVA3D is a <strong>high-quality unconditional 3D human generative model</strong> that only requires
            2D image collections for training.</p>
        </td>
      </tr>




      <!-- DDF -->
      <!-- <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()" bgcolor="#ffffd0"> -->
      <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='dreamfusion_image'><video width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video></div>
            <img src='images/DDF/deformation.png' width="160">
          </div>
          <!-- <script type="text/javascript">
            function dreamfusion_start() {
              document.getElementById('dreamfusion_image').style.opacity = "1";
            }

            function dreamfusion_stop() {
              document.getElementById('dreamfusion_image').style.opacity = "0";
            }
            dreamfusion_stop()
          </script> -->
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://nirvanalan.github.io/projects/DDF/index.html">
            <papertitle>DDF: Correspondence Distillation from NeRF-Based GAN</papertitle>
          </a>
          <br>
          <strong>Yushi Lan</strong>,
          <a href='https://www.mmlab-ntu.com/person/ccloy/' target='_blank'>Chen Change Loy</a>,
          <a href='https://daibo.info/' target='_blank'>Bo Dai</a>
          <br>
          <em>IJCV</em>, 2022
          <br>
          <a href="https://nirvanalan.github.io/projects/DDF/index.html">project page</a>
          /
          <a href="https://arxiv.org/abs/2212.09735">arXiv</a>
          /
          <a href="https://rdcu.be/dm0mL">Springer</a>
          <!-- / -->
          <!-- <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
          <p></p>
          <p>
            We study dense correspondence, which plays a key role in 3D scene understanding but has been ignored in NeRF
            research.
            DDF presents a novel way to <strong>distill dense NeRF correspondence from pre-trained NeRF GAN
              unsupervisedly.</strong>
          </p>
        </td>
      </tr>

      <!-- MagnifierNet -->
      <!-- <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()" bgcolor="#ffffd0"> -->
      <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='dreamfusion_image'><video width=100% height=100% muted autoplay loop>
                <source src="images/dreamfusion.mp4" type="video/mp4">
                Your browser does not support the video tag.
              </video></div>
            <img src='images/magnifiernet.png' width="160">
          </div>
          <!-- <script type="text/javascript">
            function dreamfusion_start() {
              document.getElementById('dreamfusion_image').style.opacity = "1";
            }

            function dreamfusion_stop() {
              document.getElementById('dreamfusion_image').style.opacity = "0";
            }
            dreamfusion_stop()
          </script> -->
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://nirvanalan.github.io/projects/DDF/index.html">
            <papertitle>Magnifier: Towards Semantic Adversary and Fusion for Person Re-identification</papertitle>
          </a>
          <br>
          <strong>Yushi Lan*</strong>,
          <a href="https://scholar.google.com/citations?user=gERzisMAAAAJ&hl=en" target="_blank">Yuan Liu*</a>,
          <a href="https://scholar.google.com/citations?user=AUFcWtwAAAAJ&hl=en" target="_blank">Xinchi Zhou</a>,
          <a href="https://scholar.google.com.hk/citations?user=UXFCqloAAAAJ&hl=en" target="_blank">Maoqing Tian</a>,
          <a href="https://scholar.google.com/citations?user=vInibgEAAAAJ&hl=en" target="_blank">Xuesen Zhang</a>,
          <a href="https://scholar.google.com/citations?user=afbbNmwAAAAJ&hl=en" target="_blank">Shuai Yi</a>,
          <a href="https://www.ee.cuhk.edu.hk/~hsli/" target="_blank">Hongsheng Li</a>,
          <br>
          <em>BMVC</em>, 2020
          <br>
          <!-- <a href="https://nirvanalan.github.io/projects/DDF/index.html">project page</a>
          / -->
          <a href="https://arxiv.org/abs/2002.10979">arXiv</a>
          /
          <a href="https://github.com/NIRVANALAN/magnifiernet_reid">Code</a>
          <!-- / -->
          <!-- <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a> -->
          <p></p>
          <p>
            We propose MagnifierNet, a triple-branch network which accurately mines details from whole to parts in person re-identification (ReID).
          </p>
        </td>
      </tr>





      <!-- template -->
      <!-- <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()" bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='dreamfusion_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/dreamfusion.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/dreamfusion.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function dreamfusion_start() {
                      document.getElementById('dreamfusion_image').style.opacity = "1";
                    }

                    function dreamfusion_stop() {
                      document.getElementById('dreamfusion_image').style.opacity = "0";
                    }
                    dreamfusion_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://dreamfusion3d.github.io/">
                    <papertitle>DreamFusion: Text-to-3D using 2D Diffusion</papertitle>
                  </a>
                  <br>
                  <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
                  <a href="https://www.ajayj.com/">Ajay Jain</a>,
                  <strong>Jonathan T. Barron</strong>,
                  <a href="https://bmild.github.io/">Ben Mildenhall</a>
                  <br>
                  <em>arXiv</em>, 2022
                  <br>
                  <a href="https://dreamfusion3d.github.io/">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
                  /
                  <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a>
                  <p></p>
                  <p>
                    We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D
                    generative modeling.
                  </p>
                </td>
              </tr> -->


    </tbody>
  </table>

  <!-- 
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td>
          <heading>Misc</heading>
        </td>
      </tr>
    </tbody>
  </table> -->
  <table width="100%" align="center" border="0" cellpadding="20">
    <!-- <tbody> -->

    <!-- <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
                <td width="75%" valign="center">
                  <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                  <br>
                  <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member,
                    CVPR 2021</a>
                  <br>
                  <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                  <br>
                  <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
                </td> -->
    <!-- </tr> -->
    <!-- <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/cs188.jpg" alt="cs188">
                </td>
                <td width="75%" valign="center">
                  <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor,
                    CS188 Spring 2011</a>
                  <br>
                  <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor,
                    CS188 Fall 2010</a>
                  <br>
                  <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd
                    Edition</a>
                </td>
              </tr> -->


    <!-- <tr>
                <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                  <heading>Basically <br> Blog Posts</heading>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                  <br>
                  <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain
                    Functions</a>
                  <br>
                  <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                </td>
              </tr> -->


    </tbody>
  </table>

  <table style="width:70%;border:0px;border-spacing:0px;">
  <!-- <table > -->
    <tbody>
      <tr>
        <td style="padding:0px">
          <br>
          <p style="text-align:right;font-size:small;">
            Design and source code from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's
              website</a>
          </p>
        </td>
      </tr>
    </tbody>
  </table>
  </td>
  </tr>
  </table>
</body>

</html>
